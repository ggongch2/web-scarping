import json
from urllib.request import urlopen
from bs4 import BeautifulSoup, Tag
from urllib.request import HTTPError 
import re 

# 초기문서 -> 초기 문서에 있는 모든 링크 수집 -> 하나하나마다 문서의 편집자의 국가, 지역을 조사함(사진일경우 제외) -> link가 빌때까지 반복 

def getCountry(ipAddress, type) :
    response = urlopen("http://ip-api.com/json/"+ipAddress).read()
    responseJson = json.loads(response)
    #print(responseJson) 
    if type == "Country" : 
        return responseJson.get("countryCode")
    elif type == "Region" : 
        region = responseJson.get("regionName") + " "+ responseJson.get("city")
        return region
 
def getlinks(url) :
      html = urlopen(url) 
      bsObj = BeautifulSoup(html, "html.parser")
      link_compliation = set()
      pattern = re.compile('/wiki/')
      link = bsObj.find('div', id ="bodyContent").find_all('a')
      for each in link :
        if 'href' in each.attrs :
            link_text = each.get("href")
            link_compliation.append(link_text) 
      return link_compliation 

def historyIPs(url) :
    




links = "#초기주소"

