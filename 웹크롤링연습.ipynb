{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9r9q9O+Pnyl7MvwpVJSFc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ggongch2/web-scarping/blob/main/%EC%9B%B9%ED%81%AC%EB%A1%A4%EB%A7%81%EC%97%B0%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install selenium"
      ],
      "metadata": {
        "id": "tWhEOp94m-or",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c44730d-64ad-4c60-88bd-a4361252290e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.27.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.28.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2024.12.14)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (24.3.0)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Downloading selenium-4.27.1-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.28.0-py3-none-any.whl (486 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.3/486.3 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: sortedcontainers, wsproto, outcome, trio, trio-websocket, selenium\n",
            "Successfully installed outcome-1.3.0.post0 selenium-4.27.1 sortedcontainers-2.4.0 trio-0.28.0 trio-websocket-0.11.1 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "WuNG4Z8ynECC",
        "outputId": "73efe2e0-24b8-4032-ebbd-350ed80ca84f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#최초 1회\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver '/content/drive/MyDrive/Colab Notebooks' #\n",
        "!pip install chromedriver-autoinstaller\n"
      ],
      "metadata": {
        "id": "uPWZH0U1nfPe",
        "outputId": "8f13fd00-fca9-46a5-f6a4-6619fcae89d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  apparmor chromium-browser libfuse3-3 liblzo2-2 libudev1 snapd squashfs-tools systemd-hwe-hwdb\n",
            "  udev\n",
            "Suggested packages:\n",
            "  apparmor-profiles-extra apparmor-utils fuse3 zenity | kdialog\n",
            "The following NEW packages will be installed:\n",
            "  apparmor chromium-browser chromium-chromedriver libfuse3-3 liblzo2-2 snapd squashfs-tools\n",
            "  systemd-hwe-hwdb udev\n",
            "The following packages will be upgraded:\n",
            "  libudev1\n",
            "1 upgraded, 9 newly installed, 0 to remove and 48 not upgraded.\n",
            "Need to get 30.2 MB of archives.\n",
            "After this operation, 123 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.4 [598 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblzo2-2 amd64 2.10-2build3 [53.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 squashfs-tools amd64 1:4.5-3build1 [159 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.12 [78.2 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.12 [1,557 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfuse3-3 amd64 3.10.5-1build1 [81.2 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 snapd amd64 2.66.1+22.04 [27.6 MB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [49.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [2,308 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n",
            "Fetched 30.2 MB in 1s (22.6 MB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package apparmor.\n",
            "(Reading database ... 124565 files and directories currently installed.)\n",
            "Preparing to unpack .../apparmor_3.0.4-2ubuntu2.4_amd64.deb ...\n",
            "Unpacking apparmor (3.0.4-2ubuntu2.4) ...\n",
            "Selecting previously unselected package liblzo2-2:amd64.\n",
            "Preparing to unpack .../liblzo2-2_2.10-2build3_amd64.deb ...\n",
            "Unpacking liblzo2-2:amd64 (2.10-2build3) ...\n",
            "Selecting previously unselected package squashfs-tools.\n",
            "Preparing to unpack .../squashfs-tools_1%3a4.5-3build1_amd64.deb ...\n",
            "Unpacking squashfs-tools (1:4.5-3build1) ...\n",
            "Preparing to unpack .../libudev1_249.11-0ubuntu3.12_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.12) over (249.11-0ubuntu3.10) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.12) ...\n",
            "Selecting previously unselected package udev.\n",
            "(Reading database ... 124773 files and directories currently installed.)\n",
            "Preparing to unpack .../udev_249.11-0ubuntu3.12_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.12) ...\n",
            "Selecting previously unselected package libfuse3-3:amd64.\n",
            "Preparing to unpack .../libfuse3-3_3.10.5-1build1_amd64.deb ...\n",
            "Unpacking libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Selecting previously unselected package snapd.\n",
            "Preparing to unpack .../snapd_2.66.1+22.04_amd64.deb ...\n",
            "Unpacking snapd (2.66.1+22.04) ...\n",
            "Setting up apparmor (3.0.4-2ubuntu2.4) ...\n",
            "Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n",
            "Setting up liblzo2-2:amd64 (2.10-2build3) ...\n",
            "Setting up squashfs-tools (1:4.5-3build1) ...\n",
            "Setting up udev (249.11-0ubuntu3.12) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Setting up snapd (2.66.1+22.04) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service → /lib/systemd/system/snapd.apparmor.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service → /lib/systemd/system/snapd.autoimport.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service → /lib/systemd/system/snapd.core-fixup.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service → /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Unit /lib/systemd/system/snapd.seeded.service is added as a dependency to a non-existent unit cloud-final.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service → /lib/systemd/system/snapd.service.\n",
            "Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer → /lib/systemd/system/snapd.snap-repair.timer.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket → /lib/systemd/system/snapd.socket.\n",
            "Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service → /lib/systemd/system/snapd.system-shutdown.service.\n",
            "Selecting previously unselected package chromium-browser.\n",
            "(Reading database ... 125002 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "=> Installing the chromium snap\n",
            "==> Checking connectivity with the snap store\n",
            "===> System doesn't have a working snapd, skipping\n",
            "Unpacking chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../systemd-hwe-hwdb_249.11.5_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Processing triggers for udev (249.11-0ubuntu3.12) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "cp: cannot create regular file '/content/drive/MyDrive/Colab Notebooks': No such file or directory\n",
            "Collecting chromedriver-autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from chromedriver-autoinstaller) (24.2)\n",
            "Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: chromedriver-autoinstaller\n",
            "Successfully installed chromedriver-autoinstaller-0.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "https://velog.io/@kite_day/colab-%EC%97%90%EC%84%9C-%EC%9B%B9-%ED%81%AC%EB%A1%A4%EB%A7%81%ED%95%98%EA%B8%B0-selenium\n",
        "https://m.blog.naver.com/sinx2233/223223626622 # selenium 응답 확인 seleniumwire\n",
        "https://velog.io/@sangyeon217/selenium-webdriver-wait webdriverwait\n"
      ],
      "metadata": {
        "id": "yap-5-rP4KUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HOSt56xNlqm9"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup, Tag\n",
        "import requests\n",
        "import re\n",
        "import random\n",
        "import sys\n",
        "import selenium\n",
        "import time\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium import webdriver"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chrome_path = \"/content/drive/MyDrive/Colab Notebooks/chromedriver\"\n",
        "sys.path.insert(0,chrome_path)\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless') # ensure GUI is off\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')  # set path to chromedriver as per your configuration\n",
        "chrome_options.add_argument('lang=ko_KR') # 한국어\n"
      ],
      "metadata": {
        "id": "cdQNQiORntHm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤문서에 방문해서 그문서에 기여한 사람 집계\n",
        "# 다른 문서에 기여한 사람 집계 -> 모두 나라별\n",
        "# 그래서 나라별 기여도가 비슷할수록 비슷한 문서/연관성이 높다고 볼수 있지않을까?\n",
        "\n",
        "# 외부링크들을 모아서 Set에 넣고\n",
        "#위키 재밌는 문서 찾기\n",
        "# 랜덤문서 찾고 연관 문서가 다양한 것 ? 많은것?"
      ],
      "metadata": {
        "id": "3qYYpHVLvfgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_href_name(url) :\n",
        "  if url is not None :\n",
        "    if url.startswith(\"https://en.wikipedia.org/wiki/\") :\n",
        "      parts = url.split(\"/\")\n",
        "      wiki_index = parts.index(\"wiki\")\n",
        "      if \"Wikipedia\" not in parts[wiki_index+1] :\n",
        "        return parts[wiki_index+1]\n",
        "  else :\n",
        "    return None\n",
        "#cite도 없어야함, category 이것도 없어야함\n",
        "#나머지 중복링크는 직접 수작업으로 처리\n",
        "\"\"\"\n",
        "# 아래는 예시\n",
        "urls = [\n",
        "    \"https://en.wikipedia.org/wiki/Geographic_coordinate_system\",\n",
        "    \"https://en.wikipedia.org/wiki/New_South_Wales\",\n",
        "    \"https://en.wikipedia.org/wiki/Main_Page\",  # 정상적인 URL\n",
        "    \"https://en.wikipedia.org/\",  # wiki가 없는 경우\n",
        "    \"https://www.example.com/page1\", # 다른 URL\n",
        "    \"https://en.wikipedia.org/wiki/\",\n",
        "    \"https://en.wikipedia.org/wiki/Wollemi_National_Park\",\n",
        "    \"https://en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License\",\n",
        "    \"https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Universal_Code_of_Conduct\"\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "for url in urls :\n",
        "  print(get_href_name(url))\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "dpQOPYiddw-1",
        "collapsed": true,
        "outputId": "7b80829c-f22d-40d8-b6bb-18d3ef542683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# 아래는 예시\\nurls = [\\n    \"https://en.wikipedia.org/wiki/Geographic_coordinate_system\",\\n    \"https://en.wikipedia.org/wiki/New_South_Wales\",\\n    \"https://en.wikipedia.org/wiki/Main_Page\",  # 정상적인 URL\\n    \"https://en.wikipedia.org/\",  # wiki가 없는 경우\\n    \"https://www.example.com/page1\", # 다른 URL\\n    \"https://en.wikipedia.org/wiki/\",\\n    \"https://en.wikipedia.org/wiki/Wollemi_National_Park\",\\n    \"https://en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License\",\\n    \"https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Universal_Code_of_Conduct\"\\n\\n]\\n\\n\\nfor url in urls :\\n  print(get_href_name(url))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#wiki 에서 #cite_note와 Category: 는 제외\n",
        "\n",
        "not_include = ['Category:', '#cite_note', '#cite_ref', 'File:', '#bodyContent']"
      ],
      "metadata": {
        "id": "KJCtMkS3PbJH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basic_title = list({'Special:RecentChangesLinked', 'Special:MyContributions', 'Main_Page', 'Special:RecentChanges', 'Special:Search', 'Special:Random', 'Special:SpecialPages', 'Help:Category', 'Help:Introduction', 'Help:Contents', 'Special:WhatLinksHere', 'Special:MyTalk', 'Portal:Current_events'})\n",
        "basic_urls = ['https://en.wikipedia.org/wiki/Special:RecentChangesLinked', 'https://en.wikipedia.org/wiki/Special:MyContributions', 'https://en.wikipedia.org/wiki/Main_Page', 'https://en.wikipedia.org/wiki/Special:RecentChanges', 'https://en.wikipedia.org/wiki/Special:Search', 'https://en.wikipedia.org/wiki/Special:Random', 'https://en.wikipedia.org/wiki/Special:SpecialPages', 'https://en.wikipedia.org/wiki/Help:Category', 'https://en.wikipedia.org/wiki/Help:Introduction', 'https://en.wikipedia.org/wiki/Help:Contents', 'https://en.wikipedia.org/wiki/Special:WhatLinksHere', 'https://en.wikipedia.org/wiki/Special:MyTalk', 'https://en.wikipedia.org/wiki/Portal:Current_events']"
      ],
      "metadata": {
        "id": "MGKt-jzWFzIr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_href_set(driver) :\n",
        "  href_set = set()\n",
        "  #a_tag = driver.find_elements(By.TAG_NAME, 'a')\n",
        "  a_tag = driver.find_elements(By.XPATH, \"//a[not(@class='vector-toc-link' or @class='mw-file-description')]\")\n",
        "  title = get_title(driver)\n",
        "  for each in a_tag :\n",
        "    href_url = each.get_attribute('href')\n",
        "    href_value = get_href_name(href_url)\n",
        "    if href_value is not None and href_value not in basic_title and href_value is not title :\n",
        "        if not any(word in href_value for word in not_include) :\n",
        "          href_set.add(href_value)\n",
        "  return href_set\n",
        "\n",
        "# href 링크 모으기. class=new인건 수집x. /wiki/... 형식이여야함\n",
        "\n",
        "# 링크 들어가기전에 이미 있는 애면 수집 x"
      ],
      "metadata": {
        "id": "WSOB5okIxmBh",
        "collapsed": true
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_wiki_page() :\n",
        "  url = \"https://en.wikipedia.org/wiki/Special:Random\"\n",
        "  driver = webdriver.Chrome(options = chrome_options)\n",
        "  driver.get(url)\n",
        "  html = driver.page_source\n",
        "  soup = BeautifulSoup(html, 'html.parser')\n",
        "  return driver"
      ],
      "metadata": {
        "id": "mjivM89ExmDj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class"
      ],
      "metadata": {
        "id": "6GcPSpBg71L6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_title(driver) :\n",
        "  return driver.find_element(By.ID, 'firstHeading').text\n"
      ],
      "metadata": {
        "id": "B3aLo_r0Mk8z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def how_many_href(driver) :\n",
        "  a_tag_set = get_href_set(driver)\n",
        "  return len(a_tag_set)\n",
        "  # a_tag 수를 알려면 h_set을 알아야하고, get_href_set을 여러번 돌려야한다는 것을 안다면, 매우 비효율적인 함수\n",
        "  # 자손을 알때는 유용한데 이미 주어진경우는 h_set을 저장해두는 것이 효율적일수도\n",
        "  # 전체 h_ref_list에 dict 원소로, key:문서제목, value:href_set으로 저장\n",
        "  # 아예 class로 문서, href_set을 저장할수있지 않을까?, 메서드는 한문서에서 다른문서로 넘어가는거로"
      ],
      "metadata": {
        "id": "5omSBR2JD5t3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_href_url(href_value) :\n",
        "  return \"https://en.wikipedia.org/wiki/\"+href_value"
      ],
      "metadata": {
        "id": "6As7R5-3I1Qg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# key로 href_set에서 key:링크 이름, value : how_many_href(url) 로 해보기\n",
        "#   get_title로 아예 key 이름을 해버리기?"
      ],
      "metadata": {
        "id": "G72eyT3aHJ0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "driver = random_wiki_page()\n",
        "\n",
        "start_href = get_title(driver)\n",
        "\n",
        "h_set = get_href_set(driver)\n",
        "h_dict = dict()\n",
        "\n",
        "h_dict[start_href] = how_many_href(driver)\n",
        "\n",
        "for each in h_set :\n",
        "  driver.get(make_href_url(each))\n",
        "  h_dict[each] = how_many_href(driver)\n",
        "\n",
        "print(h_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIOjKWOsD5ri",
        "outputId": "e7258b30-208d-47ce-f807-00617a53faf5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Mithileshwar Nikash': 44, 'Template_talk:Dhanusa_District': 6, 'Gaunpalika': 300, 'Dhanusa_District': 258, 'Village_development_committee_(Nepal)': 141, 'Municipalities': 568, 'Zones_of_Nepal': 166, 'Sabaila,_Nepal': 43, 'Template_talk:Dhanusha-geo-stub': 10, 'Aurahi_Rural_Municipality,_Dhanusa': 38, 'Janakpur': 199, 'Ganeshman_Charanath': 51, 'Municipalities_of_Nepal': 566, 'Dhanusha_District': 257, 'Mukhiyapatti_Musharniya_Rural_Municipality': 62, 'UTC%2B5:45': 91, 'Template:Dhanusa_District': 29, 'Janaknandini_Rural_Municipality': 55, 'Nepal_Time': 97, 'Mithila_Bihari': 53, 'Districts_of_Nepal': 344, 'Administrative_divisions_of_Nepal': 243, 'Chhireshwarnath': 69, 'Nagarain': 70, 'Geographic_coordinate_system': 295, 'Time_zone': 990, 'Special:EditPage': 2, 'Kamala_Municipality,_Dhanusha': 53, 'Template:Dhanusha-geo-stub': 14, 'Mithileshwar_Nikash#': 43, 'Talk:Mithileshwar_Nikash': 10, 'Janakpur_Zone': 73, '1991_Nepal_census': 15, 'Dhanusadham': 53, 'Mithileshwar_Nikash?action=edit': 62, 'Digital_Himalaya': 29, 'Bateshwar_Rural_Municipality': 50, 'Bideha,_Dhanusa': 56, 'Hansapur,_Dhanusa': 52, 'Mithileshwar_Nikash': 43, 'Shahidnagar,_Dhanusha': 67, 'Dhanauji_Rural_Municipality': 56, 'Nepal': 1052, 'Mithila_Municipality': 49, 'Lakshminiya_Rural_Municipality': 49}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rNode_info :\n",
        "  driver = random_wiki_page()\n",
        "\n",
        "  start_href = get_title(driver)\n",
        "\n",
        "\n",
        "  h_set = get_href_set(driver)\n",
        "  h_dict = dict()\n",
        "\n",
        "  h_dict[start_href] = how_many_href(driver)\n",
        "\n",
        "  for each in h_set :\n",
        "    driver.get(make_href_url(each))\n",
        "    h_dict[each] = how_many_href(driver)\n",
        "\n",
        "  print(h_dict)"
      ],
      "metadata": {
        "id": "byWLLlioHJ3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # 아예 class로 그래프 형태로 저장하여 문서, href_set을 저장할수있지 않을까?, 메서드는 한문서에서 다른문서로 넘어가는거로 <- 너무 범위가 커지는듯\n",
        "  #차라리 문서 하나를 객체로 해서 href_set과 title을 관리?\n",
        "  # get_url을 할때마다 class에 접근해서 해당 객체가 존재하는 경우 그대로 가져다씀\n",
        "  # 차라리 위키가 가진 연결성? 한링크에서 다른 링크까지 가는데 걸리는횟수? 그래프 시각화\n",
        "\n",
        "\n",
        "# 일단 새 검색을 하면 노드를 생성 / 노드가 있는지 검사 -> 생성인 경우\n",
        "#                                                      ->  노드가 있는 경우 ->\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, title, href_set) :\n",
        "      self.title = None\n",
        "      self.href_set = None\n",
        "  #만약 해당하는 이름의 title을 가진 객체가 있을경우 href_set을 return\n",
        "    def get_Node_hset(self) :\n",
        "      return self.href_set\n",
        "    def get_Node_title(self) :\n",
        "      return self.title\n",
        "    #21343313212.get\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Vxi1D7pjD5wX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "요약\n",
        "\n",
        "그래프로 위키들 연결 상태를 표시해보기 ?  -> 시각화해서 함 보기\n",
        "\n",
        "로직\n",
        "\n",
        "각각의 문서를 노드로 생각, 노드 - 노드 그래프로 구현, 연결성을 한번보기\n",
        "\n",
        "주요 필요 함수로직\n",
        "\n",
        "드라이버로 랜덤에 접속 -> 이미 있음 -> 종료\n",
        "                       -> 없음 -> 노드(이미 생섣돼 있음) 에 hset 담기, 연결 간선수 기록 -> hset에 있는애들 대상으로 다시한번 하기\n",
        "\n",
        "새 주소에 접속할때마다 노드 체크하기 -> 있으면 넘어가기\n",
        "                                     -> 없으면 생성 (그러나 기본정보는 비워두고 나중에 채우기 )  -> .get 함수를 오버로딩해서 관리하기 ?\n",
        "\n"
      ],
      "metadata": {
        "id": "Le2obgTUD5zm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}